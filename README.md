AI-Powered Second Brain
Intelligent PDF Question-Answering System using Gemini 2.0 Flash + Pinecone + FastAPI

Twinmind is an AI-powered knowledge system that ingests PDFs, chunks and embeds their content, stores them in Pinecone, and enables users to query the documents using natural language.
Built with FastAPI, Gemini Flash, Pinecone, and a lightweight frontend chat UI.

ğŸš€ Features
ğŸ”¹ AI-Driven PDF Understanding

Upload any PDF (books, notes, reports, research papers)

System extracts text â†’ chunks â†’ embeds using Gemini Embeddings (1536-dim)

Stores semantic vectors in Pinecone

ğŸ”¹ Chat with Your Documents

Ask natural-language questions

Retrieves relevant chunks from Pinecone

Sends contextual prompt to Gemini Flash 2.0

Returns accurate answers grounded in your documents

ğŸ”¹ Modern, Fast Backend

Built with FastAPI

CORS enabled for frontend integration

Async and optimized for performance

ğŸ”¹ Beautiful Minimal Frontend

Simple chat interface (index.html)

PDF upload with progress indicator

Real-time user â†” AI conversation

Error messages displayed cleanly

ğŸ”¹ Robust Error Handling

Handles:

Extraction issues

Embedding failures

Rate limits

Empty context cases

Pinecone mismatches

Backend logs show detailed debug info

ğŸ”¹ Optimized for Speed

Embeds only first 10 meaningful chunks for fast performance

Uses Gemini Embeddings (1536d) compatible with Pinecone index

Added throttling/logging to prevent timeouts

ğŸ§  System Architecture
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Frontend   â”‚
            â”‚ (index.html) â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        FastAPI         â”‚
        â”‚   /upload/pdf          â”‚
        â”‚   /query               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    Backend Processing Flow    â”‚
   â”‚ 1. Extract PDF text           â”‚
   â”‚ 2. Chunk text (N=800, overlap)â”‚
   â”‚ 3. Embed chunks (1536 dims)   â”‚
   â”‚ 4. Store in Pinecone          â”‚
   â”‚ 5. Query: embed â†’ search â†’ LLMâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Pinecone     â”‚
         â”‚ Vector Database â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Gemini 2.0 Flash     â”‚
       â”‚  (Context QA Engine)  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“ Project Structure
Twinmind/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py           # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ llm.py            # Gemini Flash wrapper
â”‚   â”‚   â”œâ”€â”€ embeddings.py     # Gemini embedding logic
â”‚   â”‚   â”œâ”€â”€ vector_store.py   # Pinecone upsert/query
â”‚   â”‚   â”œâ”€â”€ pdf_utils.py      # PDF extraction
â”‚   â”‚   â”œâ”€â”€ config.py         # Env + settings
â”‚   â”‚   â””â”€â”€ chunker.py        # Text chunking helpers
â”‚   â”œâ”€â”€ .env                  # API keys (ignored in Git)
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ frontend/
    â””â”€â”€ index.html             # Chat UI + PDF upload

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/SomnathTuppada/Twinmind.git
cd Twinmind/backend

2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
.\.venv\Scripts\activate

3ï¸âƒ£ Install Python Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Setup .env file

Create backend/.env:

GEMINI_API_KEY=YOUR_GEMINI_KEY
PINECONE_API_KEY=YOUR_PINECONE_KEY
PINECONE_INDEX=second-brain
PINECONE_ENVIRONMENT=us-east-1


(Never push .env to Git!)

5ï¸âƒ£ Run the Backend
uvicorn app.main:app --reload --port 8000

6ï¸âƒ£ Run Frontend

Open file:

frontend/index.html


Browser loads chat UI.

ğŸ’¬ Usage
1. Upload a PDF

Click Upload PDF, wait 10â€“30 seconds.

2. Ask questions

Example:

Summarize the uploaded PDF.

What does the document say about Artificial Intelligence?

3. AI Responds

System extracts context â†’ retrieves chunks â†’ uses Gemini â†’ returns the answer.

ğŸ” Security Notes

API keys are NOT included in repo

.gitignore protects .env & .venv

All sensitive data is handled on backend

ğŸ›  Tech Stack
Component	Technology
Frontend	HTML, CSS, JavaScript
Backend	FastAPI
Embeddings	Gemini Embedding (1536d)
LLM	Gemini 2.0 Flash
Vector DB	Pinecone
Runtime	Python 3.11
Tools	pdfplumber, pydantic, CORS middleware
ğŸŒŸ Future Enhancements

Multi-document upload system

Document search & deletion

Streaming AI responses

Chat history saved per user

UI dark/light theme toggle

Deployment on Render/Vercel

ğŸ§‘â€ğŸ’» Author

Somnath Tuppada
Built as part of an AI-powered knowledge assistant system.
GitHub: https://github.com/SomnathTuppada
